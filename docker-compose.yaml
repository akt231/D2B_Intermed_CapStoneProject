version: "3.8"

networks: 
  appnet:
    driver: bridge

services:
  zookeeper:
    build:
      context: ./zookeeper
      dockerfile: Dockerfile
    container_name: zookeeper
    #working_dir: /apps/d2b_cap/zookeeper
    #volumes:
    #  - "zookeeper_logs:/apps/d2b_cap/kafka_log" #https://github.com/rafaelzimmermann/learn-kafka-with-python/blob/master/docker-compose.yml
    networks: 
      - appnet
    healthcheck:
      test: nc -z localhost:2181 || exit -1
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: "confluentinc/cp-enterprise-kafka:latest"
    container_name: broker
    working_dir: /apps/d2b_cap/kafka
    volumes:
      - ./kafka:/apps/d2b_cap/kafka
      - "kafka_logs:/kafka_log"
    networks: 
      - appnet
    ports:
      - '9092:9092'
      - '29094:29094'
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: nc -z localhost:9092 || exit -1
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    environment:
      KAFKA_BROKER_ID: 0
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      #KAFKA_LISTENERS: LISTENER_01://kafka0:29092,LISTENER_02://kafka0:9092,LISTENER_03://kafka0:29094
      KAFKA_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      #KAFKA_ADVERTISED_LISTENERS: LISTENER_01://kafka0:29092,LISTENER_02://localhost:9092,LISTENER_03://never-gonna-give-you-up:29094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      #KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_01:PLAINTEXT,LISTENER_02:PLAINTEXT,LISTENER_03:PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      #KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_01
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_CREATE_TOPICS: '${d2b_kafka_producer_topic}:1:1'
      KAFKA_ADVERTISED_HOST_NAME: host.docker.internal # change to 172.17.0.1 if running on Ubuntu
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
    #volumes:
    #  - /var/run/docker.sock:/var/run/docker.sock

  producer:
    build:
      context: ./finnhub_producer
      dockerfile: Dockerfile
    container_name: finnhub_producer
    restart: always
    depends_on:
      zookeeper:
        condition: service_healthy
      broker:
        condition: service_healthy
    healthcheck:
      test: nc -z localhost:80 || exit -1
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks: 
      - appnet
    ports:
      - '80:80'
    volumes:
      - app_producer:/apps/d2b_cap/finnhub_producer
    working_dir: /apps/d2b_cap/finnhub_producer
    #entrypoint: 
    #  - bash 
    #  - -c 
    #  - |
    #    echo 'Giving Kafka a bit of time to start upâ€¦'
    #    sleep 30
    #    # Run the client code
    #    python ./finnhub_producer.py broker:9092


  #spark:
  #  image: bitnami/spark:3
  #  container_name: spark_master
  #  networks: 
  #    - appnet
  #  ports:
  #    - 8085:8080
  #  environment:
  #    - SPARK_UI_PORT=8080
  #    - SPARK_MODE=master
  #    - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #    - SPARK_RPC_ENCRYPTION_ENABLED=no
  #  volumes:
  #    - ./:/home
  #    - spark-data:/opt/bitnami/spark/data

volumes:
  zookeeper_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./kafka/logs
  kafka_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./kafka/logs
  app_producer:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./finnhub_producer

