version: '2'

networks: 
  appnet:
    driver: bridge
    ipam:
        driver: default
        config:
            - subnet: "172.18.0.0/16"


services:
  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:7.3.0
    ports:
      - "2181:2181"
      - "8078:8080"
      - "3181:3181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      #KAFKA_OPTS: "-Dzookeeper.admin.enableServer=false -Dzookeeper.4lw.commands.whitelist=ruok"
    restart: always
    networks: 
      appnet:
        ipv4_address: 172.18.0.2
    volumes:
      - zk-data:/var/lib/zookeeper/data
      - zk-txn-logs:/var/lib/zookeeper/log


  broker:
    container_name: broker
    hostname: broker
    image: confluentinc/cp-kafka:7.3.0
    ports:
      - "9092:9092"
      - "9101:9101"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092, PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
    restart: always
    working_dir: /home/appuser/kafka/scripts
    networks: 
      appnet:
        ipv4_address: 172.18.0.3
    volumes:
      - kafka-data:/var/lib/kafka/data
      - kafka-scripts:/home/appuser/kafka/scripts

  producer:
    container_name: producer
    hostname: producer
    build:
      context: .
      dockerfile: ./Dockerfile_producer
    ports:
      - "1488:88"
    #volumes:
    #  - app_producer:/usr/src/app/producer
    working_dir: /usr/src/app/producer
    restart: always
    networks: 
      appnet:
        ipv4_address: 172.18.0.4

  sparkm:
    container_name: sparkm
    hostname: sparkm
    build:
      context: .
      dockerfile: ./Dockerfile_spark
    command: bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MODE=master
      - SPARK_WORKLOAD=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks: 
      appnet:
        ipv4_address: 172.18.0.5
    ports:
      - "9090:8080"
      - "7077:7077"
      - "4040:4040"
      - "18080:18080"
    volumes:
      - sprk_jars:/opt/spark_jars
      - sprk_schemas:/opt/spark-schemas
      - sprk_chkpts:/opt/spark-chkpoint
      - sprk_eventlog:/opt/spark-eventlog

#  sparkw:
#    container_name: sparkw
#    hostname: sparkw  
#    build:
#      context: .
#      dockerfile: ./Dockerfile_spark
#    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://sparkm:7077
#    environment:
#      - SPARK_MODE=worker
#      - SPARK_WORKLOAD=worker
#      - SPARK_MASTER_URL=spark://spark:7077
#      - SPARK_WORKER_MEMORY=1G
#      - SPARK_WORKER_CORES=1
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no
#      - SPARK_USER=spark
#    networks: 
#      appnet:
#        ipv4_address: 172.18.0.6
#    ports:
#      - "9091:8080"
#      - "7001:7000"
#    #working_dir: /opt/spark-apps 
#    volumes:
#      - sprk_jars:/opt/spark_jars
#      - sprk_schemas:/opt/spark-schemas
#      - sprk_chkpts:/opt/spark-chkpoint

volumes:
  zk-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./kafka/logs/zk-data
  zk-txn-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./kafka/logs/zk-txn-logs
  kafka-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./kafka/logs/kafka-data
  kafka-scripts:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./kafka/scripts
  sprk_jars:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./spark/jars
  sprk_chkpts:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./spark/chkpt
  sprk_schemas:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./producer/schemas
  sprk_eventlog:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./spark/eventlog