# Using the Ubuntu image (our OS)
FROM bitnami/spark:3.4.1


USER root
# Add Dependencies for PySpark
RUN apt-get update && apt-get install -y \
        build-essential checkinstall \
        curl vim wget software-properties-common \
        bash ssh net-tools ca-certificates iputils-ping \
        python3 python3-pip \
        libffi-dev ncurses-dev \
        libncursesw5-dev \
        libssl-dev libsqlite3-dev tk-dev \
        libgdbm-dev libc6-dev libbz2-dev 
        #libreadline-gplv2-dev 

RUN pip3 install --upgrade pip

WORKDIR /opt/spark-app
COPY ./spark/run-spark-app.sh .
COPY ./spark/start-spark.sh .
COPY ./spark/sparkstreaming.py .
COPY ./spark/test01.py .
COPY ./spark/test02_stream.py .
COPY .env .
COPY requirements_spark.txt .
COPY ./spark/utils /opt/spark-app/utils

RUN chmod +x /opt/spark-app/*
RUN /opt/spark-app/start-spark.sh

RUN pip3 install --no-cache-dir -r requirements_spark.txt
RUN apt-get clean && rm -rf /var/lib/apt/lists/*
USER 1001
ENV PYTHONUNBUFFERED 1

#WORKDIR /opt/bitnami/spark
WORKDIR /opt/spark-app
CMD tail -f /tmp/java_opts.txt