# Using the Ubuntu image (our OS)
FROM bitnami/spark:3.4.0


USER root
# Add Dependencies for PySpark
RUN apt-get update && apt-get install -y \
        build-essential checkinstall \
        curl vim wget software-properties-common \
        bash ssh net-tools ca-certificates iputils-ping \
        python3 python3-pip \
        libffi-dev ncurses-dev \
        libncursesw5-dev \
        libssl-dev libsqlite3-dev tk-dev \
        libgdbm-dev libc6-dev libbz2-dev 
        #libreadline-gplv2-dev 

RUN pip3 install --upgrade pip

WORKDIR /opt/spark-app
COPY ./spark/run-spark-app.sh .
COPY ./spark/start-spark.sh .
COPY ./spark/sparkstreaming.py .
COPY ./spark/sparkx.py .
COPY ./spark/test.py .
COPY .env .
COPY requirements_spark.txt .
COPY ./rsa_key.p8 .
COPY ./spark/utils /opt/spark-app/utils



RUN pip3 install --no-cache-dir -r requirements_spark.txt
RUN apt-get clean && rm -rf /var/lib/apt/lists/*

RUN chown 1001:1001 -R /opt/spark-app/*
RUN chmod +rwx /opt/spark-app/*
RUN chmod 775 /opt/spark-app/*
RUN chmod 775 /opt/spark-app/rsa_key.p8

USER 1001

ENV PYTHONUNBUFFERED 1


WORKDIR /opt/bitnami/spark
RUN /opt/spark-app/start-spark.sh
CMD tail -f /tmp/java_opts.txt